{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project structure \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dealing with files\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For using regex expressions\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For loding img and reshaping\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Det går inte att hitta filen.\n",
      "Could Not Find C:\\Users\\sandr\\Documents\\DnnProject\\Project\\test1.zip\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('stage_1_test_images.zip'):\n",
    "    os.remove('stage_1_test_images.zip')\n",
    "if os.path.exists('stage_1_train_images.zip'):\n",
    "    os.remove('stage_1_train_images.zip')\n",
    "if os.path.exists('stage_1_train_images.zip'):\n",
    "    os.remove('test.zip')\n",
    "if os.path.exists('test'):\n",
    "    shutil.rmtree('test')\n",
    "if os.path.exists('train'):\n",
    "    shutil.rmtree('train')\n",
    "\n",
    "# Depending on your machine the following might take some seconds to run\n",
    "!unzip -q all.zip\n",
    "!unzip -q test1.zip\n",
    "!unzip -q train.zip\n",
    "\n",
    "if os.name == \"nt\": # windows\n",
    "    !move test1 test\n",
    "    !del test1.zip train.zip\n",
    "else:\n",
    "    !mv test1 test\n",
    "    !rm test1.zip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segrigate data in class directories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already have data frame\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Det går inte att hitta filen: '0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm' -> 'C:\\\\Users\\\\sandr\\\\Documents\\\\DnnProject\\\\Project\\\\stage_1_train_images\\\\Abnormal\\\\0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ae324b9a9185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Healthy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patientId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'No Lung Opacity / Not Normal'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Abnormal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pneumonia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m             \u001b[0mcopy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'"
     ]
    }
   ],
   "source": [
    "proj_path = r'C:\\Users\\sandr\\Documents\\DnnProject\\Project\\stage_1_train_images'\n",
    "\n",
    "# get a pandas data frame for training data\n",
    "try:\n",
    "    df = pd.read_csv('stage_1_detailed_class_info.csv')\n",
    "except FileNotFoundError:\n",
    "    print ('already have data frame')\n",
    "# save where you currently are (for coming back afterwards)\n",
    "old_path = os.getcwd()\n",
    "\n",
    "# cd to train directory\n",
    "try:\n",
    "    os.chdir(proj_path)\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "\n",
    "# Making directories for data for healthy, Pneumonia and abnormal classes \n",
    "if not os.path.isdir('Pneumonia'):\n",
    "    os.mkdir('Pneumonia')\n",
    "    \n",
    "if not os.path.isdir('Abnormal'):\n",
    "    os.mkdir('Abnormal')\n",
    "             \n",
    "if not os.path.isdir('Healthy'):\n",
    "    os.mkdir('Healthy')\n",
    "\n",
    "\n",
    "# Separate all in the three catigories\n",
    "for dirName, subdirList, fileList in os.walk(proj_path):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "            #print(filename[:-4])\n",
    "            #print(df.head())\n",
    "            #print(df[df['patientId'] == filename[:-4] ]['class'].tolist()[0])\n",
    "            if(df[df['patientId'] == filename[:-4] ]['class'].tolist()[0] == 'Normal' ):\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Healthy', filename))\n",
    "            elif (df[df['patientId'] == filename[:-4] ]['class'].tolist()[0] == 'No Lung Opacity / Not Normal' ):\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Abnormal', filename))\n",
    "            else:\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Pneumonia', filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make small training and validation sets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already in Training set stage 1 directory\n",
      "Filezise will be: %d kb 144896\n"
     ]
    }
   ],
   "source": [
    "# Parameters for creating your sub set\n",
    "proportion = 0.1\n",
    "randome = False\n",
    "size_hight, size_width = 256, 256 # Resizing the images\n",
    "filename = 'small_training_set_'\n",
    "\n",
    "#make sure you are in 'Training set stage 1' dir\n",
    "try:\n",
    "    os.chdir('Training set stage 1')\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "\n",
    "# Making directories for smal data set of the different classes\n",
    "if not os.path.isdir('Pneumonia_small'):\n",
    "    os.mkdir('Pneumonia_small')\n",
    "    \n",
    "if not os.path.isdir('Abnormal_small'):\n",
    "    os.mkdir('Abnormal_small')\n",
    "             \n",
    "if not os.path.isdir('Healthy_small'):\n",
    "    os.mkdir('Healthy_small')\n",
    "\n",
    "list_pneumonia_img = os.listdir('Pneumonia') \n",
    "list_abnormal_img = os.listdir('Abnormal')\n",
    "list_healthy_img = os.listdir('Healthy')\n",
    "size_small_data_set = round(len(list_pneumonia_img)*proportion)\n",
    "print('Filezise will be: %d kb', size_hight * round(size_small_data_set))\n",
    "\n",
    "if(randome):\n",
    "    sub_list_pneumonia_img = np.choice(list_pneumonia_img, [size_small_data_set], replace = False)\n",
    "    sub_list_abnormal_img = np.choice(list_abnormal_img, [size_small_data_set], replace = False)\n",
    "    sub_list_healthy_img = np.choice(list_healthy_img, [size_small_data_set], replace = False)\n",
    "else:      \n",
    "    sub_list_pneumonia_img = list_pneumonia_img[0:size_small_data_set]\n",
    "    sub_list_abnormal_img = list_abnormal_img[0:size_small_data_set]\n",
    "    sub_list_healthy_img = list_healthy_img[0:size_small_data_set]\n",
    "\n",
    "\n",
    "small_training_set_pneumonia = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "small_training_set_abnormal = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "small_training_set_healthy = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Pneumonia_small', filename + 'pneumonia')):\n",
    "    for f in sub_list_pneumonia_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Pneumonia', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_pneumonia_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Pneumonia_small', filename + 'pneumonia'), small_training_set_pneumonia, allow_pickle = False)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Abnormal_small', filename + 'abnormal')):\n",
    "    for f in sub_list_abnormal_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Abnormal', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_abnormal_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Abnormal_small', filename + 'abnormal'), small_training_set_abnormal, allow_pickle = False)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Healthy_small', filename + 'healthy')):\n",
    "    for f in sub_list_healthy_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Healthy', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_healthy_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Healthy_small', filename + 'healthy'), small_training_set_healthy, allow_pickle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = r'C:\\Users\\sandr\\Documents\\DnnProject\\Project'\n",
    "proportion = 0.1\n",
    "try:\n",
    "    os.chdir(proj_path)\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "# get a pandas data frame for training data\n",
    "try:\n",
    "    df = pd.read_csv('stage_1_train_labels.csv')\n",
    "except FileNotFoundError:\n",
    "    print ('already have data frame')\n",
    "\n",
    "list_pneumonia_img = os.listdir('Pneumonia') \n",
    "list_abnormal_img = os.listdir('Abnormal')\n",
    "list_healthy_img = os.listdir('Healthy')\n",
    "size_small_data_set = round(len(list_pneumonia_img)*proportion)    \n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already have data frame\n",
      "                                 patientId   x   y  width  height  Target\n",
      "3     003d8fa0-6bf1-40ed-b54c-ac657f8495c5 NaN NaN    NaN     NaN       0\n",
      "11    009482dc-3db5-48d4-8580-5c89c4f01334 NaN NaN    NaN     NaN       0\n",
      "12    009eb222-eabc-4150-8121-d5a6d06b8ebf NaN NaN    NaN     NaN       0\n",
      "13    00a85be6-6eb0-421d-8acf-ff2dc0007e8a NaN NaN    NaN     NaN       0\n",
      "21    00f87de5-5fe0-4921-93ea-914d7e683266 NaN NaN    NaN     NaN       0\n",
      "23    01027bc3-dc40-4165-a6c3-d6be2cb7ca34 NaN NaN    NaN     NaN       0\n",
      "34    017c7b5b-618e-4bc9-943c-04c6a988d992 NaN NaN    NaN     NaN       0\n",
      "35    019ca122-9cdf-4704-b7a9-449c8a1c263e NaN NaN    NaN     NaN       0\n",
      "39    01a4059c-22f7-4f51-8a27-50aff0b3aeb3 NaN NaN    NaN     NaN       0\n",
      "45    01aad2a6-3b93-45e3-bf37-2d73348cb6fc NaN NaN    NaN     NaN       0\n",
      "47    01b15f07-1149-4ff8-9756-bc821e41b97c NaN NaN    NaN     NaN       0\n",
      "53    01be3fe5-4a91-4c57-9af6-305966a7d0aa NaN NaN    NaN     NaN       0\n",
      "55    01c0b605-0a82-401b-9649-81252304ac45 NaN NaN    NaN     NaN       0\n",
      "59    01cc7c75-4498-43ab-b650-5553d0507f76 NaN NaN    NaN     NaN       0\n",
      "68    01e4fd43-4f2c-421f-bd68-c756dceb5742 NaN NaN    NaN     NaN       0\n",
      "71    01ef1712-90a6-4946-ad86-fc76b0cf2d3b NaN NaN    NaN     NaN       0\n",
      "73    01f0d9cc-f69e-471a-987a-be73a36e18cc NaN NaN    NaN     NaN       0\n",
      "74    01f0f4bf-e678-430e-b43d-2968e2c4976c NaN NaN    NaN     NaN       0\n",
      "75    01f11e57-5c11-4ab0-9312-d88c3826721c NaN NaN    NaN     NaN       0\n",
      "78    01f4cd36-caa1-480f-9d8c-92e80cf7b197 NaN NaN    NaN     NaN       0\n",
      "84    01fe92f7-ff87-4f9e-9077-e00e670d1b47 NaN NaN    NaN     NaN       0\n",
      "94    020fb648-3b1e-404a-a0b4-f25d6b277c1a NaN NaN    NaN     NaN       0\n",
      "98    022b7bbd-963b-49ea-afd7-b6b7986da555 NaN NaN    NaN     NaN       0\n",
      "100   0280a39c-4891-4a7b-8073-710c3f5577a3 NaN NaN    NaN     NaN       0\n",
      "101   029216c8-ea0d-47bb-88fd-bf611cc5d1fc NaN NaN    NaN     NaN       0\n",
      "104   0295573e-1bbe-4f14-83c2-32449fa79f10 NaN NaN    NaN     NaN       0\n",
      "113   02f6ab3b-7793-4d67-87e3-868911a399b7 NaN NaN    NaN     NaN       0\n",
      "119   03682e3c-d601-4e35-9ba5-06e85bba5c7c NaN NaN    NaN     NaN       0\n",
      "128   03b10fa5-e7c3-4726-818f-ecbace9da737 NaN NaN    NaN     NaN       0\n",
      "134   03da08b4-9f24-4822-8b2b-4abf27e3c9a8 NaN NaN    NaN     NaN       0\n",
      "...                                    ...  ..  ..    ...     ...     ...\n",
      "1961  1e091e21-abd1-48f4-b6f2-3e07ed47b247 NaN NaN    NaN     NaN       0\n",
      "1965  1e74323d-d449-4a93-aad8-2df912970b1c NaN NaN    NaN     NaN       0\n",
      "1968  1ebe7102-56ce-40f3-8897-5ec33f446625 NaN NaN    NaN     NaN       0\n",
      "1980  1f5f1dc7-7681-41c4-a380-a47e0c90057d NaN NaN    NaN     NaN       0\n",
      "1982  1f61f7dd-64ea-4e69-a59b-1b9624421f93 NaN NaN    NaN     NaN       0\n",
      "1983  1f6a4921-3e72-4e98-aaa2-5df79fe85c02 NaN NaN    NaN     NaN       0\n",
      "1984  1f9025ff-a538-41b0-8798-829612193eeb NaN NaN    NaN     NaN       0\n",
      "1985  1fc9ff06-f015-4fad-bb4f-e41e001294c8 NaN NaN    NaN     NaN       0\n",
      "1986  1fcc4272-c40e-447c-a15f-6cdf977716a1 NaN NaN    NaN     NaN       0\n",
      "1987  1fd2dd8d-8979-433e-901d-9a57e60ea90f NaN NaN    NaN     NaN       0\n",
      "1990  1ff1ebfc-d6d4-45bb-9d67-198e7ed13c40 NaN NaN    NaN     NaN       0\n",
      "1991  20506c1c-a29b-4535-976a-ddafb34bad52 NaN NaN    NaN     NaN       0\n",
      "1992  207560f9-0c11-46f4-b6b3-9ee68a558565 NaN NaN    NaN     NaN       0\n",
      "1997  20b8b7c9-258a-4a3f-9f1d-2548fd996b46 NaN NaN    NaN     NaN       0\n",
      "1998  20db11bd-2bd8-46d7-b2d3-77b8d4d8ec67 NaN NaN    NaN     NaN       0\n",
      "2005  2131a5d5-d3ca-4ce1-97a7-4ae34ef0d19f NaN NaN    NaN     NaN       0\n",
      "2010  21934e87-a655-4371-bf85-a8a68370de79 NaN NaN    NaN     NaN       0\n",
      "2013  21e403ae-139b-4419-b3fa-0bf13d97d245 NaN NaN    NaN     NaN       0\n",
      "2020  22576a85-b417-4d9a-ad80-115b92a3975a NaN NaN    NaN     NaN       0\n",
      "2026  2294cff0-b1e3-4895-a575-d1b77482f2a7 NaN NaN    NaN     NaN       0\n",
      "2028  229e6aef-1467-49a2-9158-49fd8acea0cf NaN NaN    NaN     NaN       0\n",
      "2029  22a72d2d-1043-4e16-9480-f64adeddb3a3 NaN NaN    NaN     NaN       0\n",
      "2030  22a849f4-c10a-4217-ad87-cdb80c34a5e5 NaN NaN    NaN     NaN       0\n",
      "2035  22cc0373-ff46-4c3c-847f-e9bd2afed4f5 NaN NaN    NaN     NaN       0\n",
      "2037  22fdcdc2-9d80-472e-b3b2-f5385004c16e NaN NaN    NaN     NaN       0\n",
      "2039  230cf514-a68f-4a2e-8d76-14756b40d4d7 NaN NaN    NaN     NaN       0\n",
      "2042  23253085-831d-41cc-b6e2-bd330d6ea44f NaN NaN    NaN     NaN       0\n",
      "2043  23309d6b-efcf-4823-8cce-3643c20114b6 NaN NaN    NaN     NaN       0\n",
      "2044  236f9fa0-0a74-492d-b9ae-45f0d685ca9b NaN NaN    NaN     NaN       0\n",
      "2050  238fdbc6-8081-4e89-a541-6c5a4f5aa232 NaN NaN    NaN     NaN       0\n",
      "\n",
      "[566 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "proj_path = r'C:\\Users\\sandr\\Documents\\Skola\\Dnnproject\\DnnProject\\Project\\Training set stage 1'\n",
    "proportion = 0.1\n",
    "try:\n",
    "    os.chdir(proj_path)\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "# get a pandas data frame for training data\n",
    "try:\n",
    "    df = pd.read_csv('stage_1_train_labels.csv')\n",
    "except FileNotFoundError:\n",
    "    print ('already have data frame')\n",
    "\n",
    "list_pneumonia_img = os.listdir('Pneumonia') \n",
    "list_abnormal_img = os.listdir('Abnormal')\n",
    "list_healthy_img = os.listdir('Healthy')\n",
    "size_small_data_set = round(len(list_pneumonia_img)*proportion)    \n",
    "list_pneumonia = list_pneumonia_img[0:size_small_data_set]\n",
    "list_abnormal = list_abnormal_img[0:size_small_data_set]\n",
    "list_healthy = list_healthy_img[0:size_small_data_set]\n",
    "\n",
    "\n",
    "for i in list_healthy:\n",
    "    list_healthy[list_healthy.index(i)] = i[:-4]\n",
    "for i in list_abnormal:\n",
    "    list_abnormal[list_abnormal.index(i)] = i[:-4]\n",
    "for i in list_pneumonia:\n",
    "    list_pneumonia[list_pneumonia.index(i)] = i[:-4]\n",
    "\n",
    "\n",
    "is_in_healthy = df['patientId'].isin(list_healthy)\n",
    "healthy_df = df[is_in_healthy]\n",
    "is_in_abnormal = df['patientId'].isin(list_abnormal) \n",
    "abnormal_df = df[is_in_abnormal]\n",
    "is_in_pneumonia = df['patientId'].isin(list_pneumonia) \n",
    "pneumonia_df = df[is_in_pneumonia]\n",
    "\n",
    "if not os.path.isfile('train_small_label.csv'):\n",
    "    frames = [healthy_df, abnormal_df, pneumonia_df]\n",
    "    small_train_lable = pd.concat(frames)\n",
    "    small_train_lable.to_csv(os.path.join(proj_path,'train_small_label.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scale = pd.read_csv('train_small_label.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
