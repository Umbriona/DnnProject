{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project structure \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# For dealing with files\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For using regex expressions\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For loding img and reshaping\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Det går inte att hitta filen.\n",
      "Could Not Find C:\\Users\\sandr\\Documents\\DnnProject\\Project\\test1.zip\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('stage_1_test_images.zip'):\n",
    "    os.remove('stage_1_test_images.zip')\n",
    "if os.path.exists('stage_1_train_images.zip'):\n",
    "    os.remove('stage_1_train_images.zip')\n",
    "if os.path.exists('stage_1_train_images.zip'):\n",
    "    os.remove('test.zip')\n",
    "if os.path.exists('test'):\n",
    "    shutil.rmtree('test')\n",
    "if os.path.exists('train'):\n",
    "    shutil.rmtree('train')\n",
    "\n",
    "# Depending on your machine the following might take some seconds to run\n",
    "!unzip -q all.zip\n",
    "!unzip -q test1.zip\n",
    "!unzip -q train.zip\n",
    "\n",
    "if os.name == \"nt\": # windows\n",
    "    !move test1 test\n",
    "    !del test1.zip train.zip\n",
    "else:\n",
    "    !mv test1 test\n",
    "    !rm test1.zip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segrigate data in class directories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already have data frame\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Det går inte att hitta filen: '0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm' -> 'C:\\\\Users\\\\sandr\\\\Documents\\\\DnnProject\\\\Project\\\\stage_1_train_images\\\\Abnormal\\\\0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ae324b9a9185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Healthy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patientId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'No Lung Opacity / Not Normal'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Abnormal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pneumonia'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m             \u001b[0mcopy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm'"
     ]
    }
   ],
   "source": [
    "proj_path = r'C:\\Users\\sandr\\Documents\\DnnProject\\Project\\stage_1_train_images'\n",
    "\n",
    "# get a pandas data frame for training data\n",
    "try:\n",
    "    df = pd.read_csv('stage_1_detailed_class_info.csv')\n",
    "except FileNotFoundError:\n",
    "    print ('already have data frame')\n",
    "# save where you currently are (for coming back afterwards)\n",
    "old_path = os.getcwd()\n",
    "\n",
    "# cd to train directory\n",
    "try:\n",
    "    os.chdir(proj_path)\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "\n",
    "# Making directories for data for healthy, Pneumonia and abnormal classes \n",
    "if not os.path.isdir('Pneumonia'):\n",
    "    os.mkdir('Pneumonia')\n",
    "    \n",
    "if not os.path.isdir('Abnormal'):\n",
    "    os.mkdir('Abnormal')\n",
    "             \n",
    "if not os.path.isdir('Healthy'):\n",
    "    os.mkdir('Healthy')\n",
    "\n",
    "\n",
    "# Separate all in the three catigories\n",
    "for dirName, subdirList, fileList in os.walk(proj_path):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "            #print(filename[:-4])\n",
    "            #print(df.head())\n",
    "            #print(df[df['patientId'] == filename[:-4] ]['class'].tolist()[0])\n",
    "            if(df[df['patientId'] == filename[:-4] ]['class'].tolist()[0] == 'Normal' ):\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Healthy', filename))\n",
    "            elif (df[df['patientId'] == filename[:-4] ]['class'].tolist()[0] == 'No Lung Opacity / Not Normal' ):\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Abnormal', filename))\n",
    "            else:\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Pneumonia', filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make small training and validation sets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already in Training set stage 1 directory\n",
      "Filezise will be: %d kb 144896\n"
     ]
    }
   ],
   "source": [
    "# Parameters for creating your sub set\n",
    "proportion = 0.1\n",
    "randome = False\n",
    "size_hight, size_width = 256, 256 # Resizing the images\n",
    "filename = 'small_training_set_'\n",
    "\n",
    "#make sure you are in 'Training set stage 1' dir\n",
    "try:\n",
    "    os.chdir('Training set stage 1')\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "\n",
    "# Making directories for smal data set of the different classes\n",
    "if not os.path.isdir('Pneumonia_small'):\n",
    "    os.mkdir('Pneumonia_small')\n",
    "    \n",
    "if not os.path.isdir('Abnormal_small'):\n",
    "    os.mkdir('Abnormal_small')\n",
    "             \n",
    "if not os.path.isdir('Healthy_small'):\n",
    "    os.mkdir('Healthy_small')\n",
    "\n",
    "list_pneumonia_img = os.listdir('Pneumonia') \n",
    "list_abnormal_img = os.listdir('Abnormal')\n",
    "list_healthy_img = os.listdir('Healthy')\n",
    "size_small_data_set = round(len(list_pneumonia_img)*proportion)\n",
    "print('Filezise will be: %d kb', size_hight * round(size_small_data_set))\n",
    "\n",
    "if(randome):\n",
    "    sub_list_pneumonia_img = np.choice(list_pneumonia_img, [size_small_data_set], replace = False)\n",
    "    sub_list_abnormal_img = np.choice(list_abnormal_img, [size_small_data_set], replace = False)\n",
    "    sub_list_healthy_img = np.choice(list_healthy_img, [size_small_data_set], replace = False)\n",
    "else:      \n",
    "    sub_list_pneumonia_img = list_pneumonia_img[0:size_small_data_set]\n",
    "    sub_list_abnormal_img = list_abnormal_img[0:size_small_data_set]\n",
    "    sub_list_healthy_img = list_healthy_img[0:size_small_data_set]\n",
    "\n",
    "\n",
    "small_training_set_pneumonia = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "small_training_set_abnormal = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "small_training_set_healthy = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Pneumonia_small', filename + 'pneumonia')):\n",
    "    for f in sub_list_pneumonia_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Pneumonia', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_pneumonia_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Pneumonia_small', filename + 'pneumonia'), small_training_set_pneumonia, allow_pickle = False)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Abnormal_small', filename + 'abnormal')):\n",
    "    for f in sub_list_abnormal_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Abnormal', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_abnormal_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Abnormal_small', filename + 'abnormal'), small_training_set_abnormal, allow_pickle = False)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Healthy_small', filename + 'healthy')):\n",
    "    for f in sub_list_healthy_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Healthy', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_healthy_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Healthy_small', filename + 'healthy'), small_training_set_healthy, allow_pickle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "proj_path = r'C:\\Users\\sandr\\Documents\\DnnProject\\Project'\n",
    "try:\n",
    "    os.chdir(proj_path)\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "# get a pandas data frame for training data\n",
    "try:\n",
    "    df = pd.read_csv('stage_1_train_labels.csv')\n",
    "except FileNotFoundError:\n",
    "    print ('already have data frame')\n",
    "\n",
    "list_healthy = os.listdir(os.path.join(proj_path,'stage_1_train_images', 'Healthy'))\n",
    "for i in list_healthy:\n",
    "    list_healthy[list_healthy.index(i)] = i[:-4]\n",
    "list_abnormal = os.listdir(os.path.join(proj_path,'stage_1_train_images', 'Abnormal'))\n",
    "for i in list_abnormal:\n",
    "    list_abnormal[list_abnormal.index(i)] = i[:-4]\n",
    "list_pneumonia = os.listdir(os.path.join(proj_path,'stage_1_train_images', 'Pneumonia'))\n",
    "for i in list_pneumonia:\n",
    "    list_pneumonia[list_pneumonia.index(i)] = i[:-4]\n",
    "\n",
    "\n",
    "is_in_healthy = df['patientId'].isin(list_healthy)\n",
    "healthy_df = df[is_in_healthy]\n",
    "print(is_in_healthy)\n",
    "is_in_abnormal = df['patientId'].isin(list_abnormal) \n",
    "abnormal_df = df[is_in_abnormal]\n",
    "is_in_pneumonia = df['patientId'].isin(list_pneumonia) \n",
    "pneumonia_df = df[is_in_pneumonia]\n",
    "\n",
    "#if not os.path.isfile('train_small_label.csv'):\n",
    "#    frames = [healthy_df, abnormal_df, pneumonia_df]\n",
    "#    small_train_lable = pd.concat(frames)\n",
    "#    small_train_lable.to_csv(os.path.join(proj_path, 'stage_1_train_images', 'train_small_label.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\sandr\\Documents\\DnnProject\\Project\\stage_1_train_images\\Healthy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
