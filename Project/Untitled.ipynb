{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project structure \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dealing with files\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For using regex expressions\n",
    "import re\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For loding img and reshaping\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Det g†r inte att hitta filen.\n",
      "Could Not Find C:\\Users\\sandr\\Documents\\Skola\\Deep Neural Networks\\Deep-Neural-Network\\Project\\test1.zip\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('stage_1_test_images.zip'):\n",
    "    os.remove('stage_1_test_images.zip')\n",
    "if os.path.exists('stage_1_train_images.zip'):\n",
    "    os.remove('stage_1_train_images.zip')\n",
    "if os.path.exists('stage_1_train_images.zip'):\n",
    "    os.remove('test.zip')\n",
    "if os.path.exists('test'):\n",
    "    shutil.rmtree('test')\n",
    "if os.path.exists('train'):\n",
    "    shutil.rmtree('train')\n",
    "\n",
    "# Depending on your machine the following might take some seconds to run\n",
    "!unzip -q all.zip\n",
    "!unzip -q test1.zip\n",
    "!unzip -q train.zip\n",
    "\n",
    "if os.name == \"nt\": # windows\n",
    "    !move test1 test\n",
    "    !del test1.zip train.zip\n",
    "else:\n",
    "    !mv test1 test\n",
    "    !rm test1.zip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segrigate data in class directories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already have data frame\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Det går inte att hitta filen: 'Training set stage 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-af1b904817db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# cd to train directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training set stage 1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Spliting data in healthy and sick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Det går inte att hitta filen: 'Training set stage 1'"
     ]
    }
   ],
   "source": [
    "# get a pandas data frame for training data\n",
    "try:\n",
    "    df = pd.read_csv('stage_1_detailed_class_info.csv')\n",
    "except FileNotFoundError:\n",
    "    print ('already have data frame')\n",
    "# save where you currently are (for coming back afterwards)\n",
    "old_path = os.getcwd()\n",
    "\n",
    "# cd to train directory\n",
    "try:\n",
    "    os.chdir('Training set stage 1')\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "\n",
    "# Making directories for data for healthy, Pneumonia and abnormal classes \n",
    "if not os.path.isdir('Pneumonia'):\n",
    "    os.mkdir('Pneumonia')\n",
    "    \n",
    "if not os.path.isdir('Abnormal'):\n",
    "    os.mkdir('Abnormal')\n",
    "             \n",
    "if not os.path.isdir('Healthy'):\n",
    "    os.mkdir('Healthy')\n",
    "\n",
    "\n",
    "# Separate all in the three catigories\n",
    "for dirName, subdirList, fileList in os.walk(os.getcwd()):\n",
    "    for filename in fileList:\n",
    "        if \".dcm\" in filename.lower():  # check whether the file's DICOM\n",
    "            #print(filename[:-4])\n",
    "            #print(df.head())\n",
    "            #print(df[df['patientId'] == filename[:-4] ]['class'].tolist()[0])\n",
    "\n",
    "            if(df[df['patientId'] == filename[:-4] ]['class'].tolist()[0] == 'Normal' ):\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Healthy', filename)\n",
    "            elif (df[df['patientId'] == filename[:-4] ]['class'].tolist()[0] == 'No Lung Opacity / Not Normal' ):\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Abnormal', filename)=\n",
    "            else:\n",
    "                shutil.move(filename, os.path.join(os.getcwd(), 'Pneumonia', filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make small training and validation sets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already in Training set stage 1 directory\n",
      "Filezise will be: %d kb 144896\n"
     ]
    }
   ],
   "source": [
    "# Parameters for creating your sub set\n",
    "proportion = 0.1\n",
    "randome = False\n",
    "size_hight, size_width = 256, 256 # Resizing the images\n",
    "filename = 'small_training_set_'\n",
    "\n",
    "#make sure you are in 'Training set stage 1' dir\n",
    "try:\n",
    "    os.chdir('Training set stage 1')\n",
    "except FileNotFoundError:\n",
    "    print('already in Training set stage 1 directory')\n",
    "\n",
    "# Making directories for smal data set of the different classes\n",
    "if not os.path.isdir('Pneumonia_small'):\n",
    "    os.mkdir('Pneumonia_small')\n",
    "    \n",
    "if not os.path.isdir('Abnormal_small'):\n",
    "    os.mkdir('Abnormal_small')\n",
    "             \n",
    "if not os.path.isdir('Healthy_small'):\n",
    "    os.mkdir('Healthy_small')\n",
    "\n",
    "list_pneumonia_img = os.listdir('Pneumonia') \n",
    "list_abnormal_img = os.listdir('Abnormal')\n",
    "list_healthy_img = os.listdir('Healthy')\n",
    "size_small_data_set = round(len(list_pneumonia_img)*proportion)\n",
    "print('Filezise will be: %d kb', size_hight * round(size_small_data_set))\n",
    "\n",
    "if(randome):\n",
    "    sub_list_pneumonia_img = np.choice(list_pneumonia_img, [size_small_data_set], replace = False)\n",
    "    sub_list_abnormal_img = np.choice(list_abnormal_img, [size_small_data_set], replace = False)\n",
    "    sub_list_healthy_img = np.choice(list_healthy_img, [size_small_data_set], replace = False)\n",
    "else:      \n",
    "    sub_list_pneumonia_img = list_pneumonia_img[0:size_small_data_set]\n",
    "    sub_list_abnormal_img = list_abnormal_img[0:size_small_data_set]\n",
    "    sub_list_healthy_img = list_healthy_img[0:size_small_data_set]\n",
    "\n",
    "\n",
    "small_training_set_pneumonia = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "small_training_set_abnormal = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "small_training_set_healthy = np.zeros([size_small_data_set, size_hight, size_width], dtype = np.float32)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Pneumonia_small', filename + 'pneumonia')):\n",
    "    for f in sub_list_pneumonia_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Pneumonia', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_pneumonia_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Pneumonia_small', filename + 'pneumonia'), small_training_set_pneumonia, allow_pickle = False)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Abnormal_small', filename + 'abnormal')):\n",
    "    for f in sub_list_abnormal_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Abnormal', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_abnormal_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Abnormal_small', filename + 'abnormal'), small_training_set_abnormal, allow_pickle = False)\n",
    "\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), 'Healthy_small', filename + 'healthy')):\n",
    "    for f in sub_list_healthy_img:\n",
    "        if \".dcm\" in f.lower():  # check whether the file's DICOM\n",
    "            # read the file\n",
    "            ds = dicom.read_file(os.path.join(os.getcwd(), 'Healthy', f))\n",
    "            # store the raw image data\n",
    "            rezise = tf.image.resize_images(np.flipud(np.reshape(ds.pixel_array,[1024,1024,1])),\n",
    "                                            [size_hight, size_width],\n",
    "                                            align_corners=False,\n",
    "                                            preserve_aspect_ratio=False)\n",
    "            small_training_set_pneumonia[sub_list_healthy_img.index(f), :, :] = tf.Session().run(rezise[:,:,0])\n",
    "    np.save(os.path.join(os.getcwd(), 'Healthy_small', filename + 'healthy'), small_training_set_healthy, allow_pickle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
